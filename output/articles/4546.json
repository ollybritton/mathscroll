{"title":"Dynamic discrete choice","summary":"Dynamic discrete choice (DDC) models, also known as discrete choice models of dynamic programming, model an agent's choices over discrete options that have future implications. Rather than assuming observed choices are the result of static utility maximization, observed choices in DDC models are assumed to result from an agent's maximization of the present value of utility, generalizing the utility theory upon which discrete choice models are based.[1]","image":"a601995d55609f2d9f5e233e36fbe9ea26011b3b.svg","url":"Dynamic_discrete_choice"}