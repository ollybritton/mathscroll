{"title":"Entropy rate","summary":"In the mathematical theory of probability, the entropy rate or source information rate of a stochastic process is, informally, the time density of the average information in a stochastic process. For stochastic processes with a countable index, the entropy rate H ( X ) {\\displaystyle H(X)} is the limit of the joint entropy of n {\\displaystyle n} members of the process X k {\\displaystyle X_{k}} divided by n {\\displaystyle n} , as n {\\displaystyle n} tends to infinity:","image":"bd232b6fb5ea803efc1154d2efb0c3fe00a4531b.svg","url":"Entropy_rate"}