{"title":"Method of moments (electromagnetics)","summary":"The method of moments (MoM), also known as the moment method and method of weighted residuals,[1] is a numerical method in computational electromagnetics. It is used in computer programs that simulate the interaction of electromagnetic fields such as radio waves with matter, for example antenna simulation programs like NEC that calculate the radiation pattern of an antenna.  Generally being a frequency-domain method,[lower-alpha 1] it involves the projection of an integral equation into a system of linear equations by the application of appropriate boundary conditions. This is done by using discrete meshes as in finite difference and finite element methods, often for the surface. The solutions are represented with the linear combination of pre-defined basis functions; generally, the coefficients of these basis functions are the sought unknowns. Green's functions and Galerkin method play a central role in the method of moments.","image":"Negative_reflection_from_meta-mirrors.jpg.webp","url":"Method_of_moments_(electromagnetics)"}