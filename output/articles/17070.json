{"title":"Yao's principle","summary":"In computational complexity theory, Yao's principle (also called Yao's minimax principle or Yao's lemma) is a way to prove lower bounds on the worst-case performance of randomized algorithms, by comparing them to deterministic (non-random) algorithms. It states that, for any randomized algorithm, there exists a probability distribution on inputs to the algorithm, so that the expected cost of the randomized algorithm on its worst-case input is at least as large as the cost of the best deterministic algorithm on a random input from this distribution. Thus, to establish a lower bound on the performance of randomized algorithms, it suffices to find an appropriate distribution of difficult inputs, and to prove that no deterministic algorithm can perform well against that distribution. This principle is named after Andrew Yao, who first proposed it.","image":"8c7e5461c5286852df4ef652fca7e4b0b63030e9.svg","url":"Yao's_principle"}