{"title":"Markov chains on a measurable state space","summary":"A Markov chain on a measurable state space is a discrete-time-homogeneous Markov chain with a measurable space as state space.","image":"d0d17680dc854c0601d4116eda25684b40a38344.svg","url":"Markov_chains_on_a_measurable_state_space"}