{"title":"Absorbing Markov chain","summary":"In the mathematical theory of probability, an absorbing Markov chain is a Markov chain in which every state can reach an absorbing state. An absorbing state is a state that, once entered, cannot be left.","image":"Drunkardâ€™s_walk.svg.png.webp","url":"Absorbing_Markov_chain"}