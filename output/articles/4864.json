{"title":"Entropy power inequality","summary":"In information theory, the entropy power inequality (EPI) is a result that relates to so-called \"entropy power\" of random variables. It shows that the entropy power of suitably well-behaved random variables is a superadditive function. The entropy power inequality was proved in 1948 by Claude Shannon in his seminal paper \"A Mathematical Theory of Communication\". Shannon also provided a sufficient condition for equality to hold; Stam (1959) showed that the condition is in fact necessary.","image":"01b35fb0f62d60277453e8a1dccaac9877b9bd39.svg","url":"Entropy_power_inequality"}