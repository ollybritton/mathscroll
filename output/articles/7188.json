{"title":"Hierarchical matrix","summary":"In numerical mathematics, hierarchical matrices (H-matrices)[1][2][3] are used as data-sparse approximations of non-sparse matrices. While a sparse matrix of dimension n {\\displaystyle n} can be represented efficiently in O ( n ) {\\displaystyle O(n)} units of storage by storing only its non-zero entries, a non-sparse matrix would require O ( n 2 ) {\\displaystyle O(n^{2})} units of storage, and using this type of matrices for large problems would therefore be prohibitively expensive in terms of storage and computing time. Hierarchical matrices provide an approximation requiring only O ( n k log ⁡ ( n ) ) {\\displaystyle O(nk\\,\\log(n))} units of storage, where k {\\displaystyle k} is a parameter controlling the accuracy of the approximation. In typical applications, e.g., when discretizing integral equations,[4][5][6][7][8][9] preconditioning the resulting systems of linear equations,[10] or solving elliptic partial differential equations,[11][12][13][14] a rank proportional to log ⁡ ( 1 / ϵ ) γ {\\displaystyle \\log(1/\\epsilon )^{\\gamma }} with a small constant γ {\\displaystyle \\gamma } is sufficient to ensure an accuracy of ϵ {\\displaystyle \\epsilon } . Compared to many other data-sparse representations of non-sparse matrices, hierarchical matrices offer a major advantage: the results of matrix arithmetic operations like matrix multiplication, factorization or inversion can be approximated in O ( n k α log ⁡ ( n ) β ) {\\displaystyle O(nk^{\\alpha }\\,\\log(n)^{\\beta })} operations, where α , β ∈ { 1 , 2 , 3 } . {\\displaystyle \\alpha ,\\beta \\in \\{1,2,3\\}.} [2]","image":"a601995d55609f2d9f5e233e36fbe9ea26011b3b.svg","url":"Hierarchical_matrix"}