{"title":"Bayesian linear regression","summary":"Bayesian linear regression is a type of conditional modeling in which the mean of one variable is described by a linear combination of other variables, with the goal of obtaining the posterior probability of the regression coefficients (as well as other parameters describing the distribution of the regressand) and ultimately allowing the out-of-sample prediction of the regressand (often labelled y {\\displaystyle y} ) conditional on observed values of the regressors (usually X {\\displaystyle X} ). The simplest and most widely used version of this model is the normal linear model, in which y {\\displaystyle y} given X {\\displaystyle X} is distributed Gaussian. In this model, and under a particular choice of prior probabilities for the parameters—so-called conjugate priors—the posterior can be found analytically. With more arbitrarily chosen priors, the posteriors generally have to be approximated.","image":"b8a6208ec717213d4317e666f1ae872e00620a0d.svg","url":"Bayesian_linear_regression"}