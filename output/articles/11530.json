{"title":"Order of accuracy","summary":"In numerical analysis, order of accuracy quantifies the rate of convergence of a numerical approximation of a differential equation to the exact solution. Consider u {\\displaystyle u} , the exact solution to a differential equation in an appropriate normed space ( V , | | | | ) {\\displaystyle (V,||\\ ||)} . Consider a numerical approximation u h {\\displaystyle u_{h}} , where h {\\displaystyle h} is a parameter characterizing the approximation, such as the step size in a finite difference scheme or the diameter of the cells in a finite element method. The numerical solution u h {\\displaystyle u_{h}} is said to be n {\\displaystyle n} th-order accurate if the error E ( h ) := | | u âˆ’ u h | | {\\displaystyle E(h):=||u-u_{h}||} is proportional to the step-size h {\\displaystyle h} to the n {\\displaystyle n} th power:[1]","image":"c3e6bb763d22c20916ed4f0bb6bd49d7470cffd8.svg","url":"Order_of_accuracy"}