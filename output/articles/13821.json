{"title":"Rényi entropy","summary":"In information theory, the Rényi entropy is a quantity that generalizes various notions of entropy, including Hartley entropy, Shannon entropy, collision entropy, and min-entropy. The Rényi entropy is named after Alfréd Rényi, who looked for the most general way to quantify information while preserving additivity for independent events.[1][2] In the context of fractal dimension estimation, the Rényi entropy forms the basis of the concept of generalized dimensions.[3]","image":"b79333175c8b3f0840bfb4ec41b8072c83ea88d3.svg","url":"Rényi_entropy"}